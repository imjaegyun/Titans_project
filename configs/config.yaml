# Titans_project/configs/config.yaml
defaults:
  - _self_
  - data: dataset
  - model: titan

trainer:
  max_epochs: 5
  gpus: 0

seed: 42
debug: false

# Titans_project/configs/data/dataset.yaml
data:
  csv_path: "/home/user/imjaegyun/Titans_model/Titans_project/datasets/DJI_0023_stab.csv"
  video_path: "/home/user/imjaegyun/Titans_model/Titans_project/datasets/DJI_0023_stab.mp4"

  train_size: 20
  val_size: 4
  train_batch_size: 4
  val_batch_size: 4

  frames_per_second: 10
  past_sec: 1

# Titans_project/configs/model/titan.yaml
model:
  # Light-weight LLM (tokenizer-only)
  lightweight_llm:
    model_name: "meta-llama/Llama-3.2-1B"  # => tokenizer만 사용
    lr: 1e-5
    use_lora: false

  # ViT(EAGLE) - 예시
  vit_eagle:
    model_name: "google/vit-base-patch16-224"
    freeze: true

  # Trajectory Encoder
  trajectory_encoder:
    input_dim: 6
    hidden_dim: 128

  # Base LLM
  base_llm:
    model_name: "meta-llama/Llama-3.2-1B"
    tokenizer_name: "meta-llama/Llama-3.2-1B"
    freeze: true
    use_lora: true

  # Titans
  titans:
    d_model: 768
    memory_depth: 2
    decoder_layers: 2
    surprise_decay: 0.9
    momentum: 0.9
    forget_alpha: 0.1

  # optimizer
  optimizer:
    lr: 1e-4
    weight_decay: 1e-2
