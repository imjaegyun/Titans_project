# Titans_project/configs/config.yaml

defaults:
  - _self_
  - data: dataset
  - model: titan

trainer:
  max_epochs: 5
  accelerator: "gpu"  # 또는 "cpu", "auto"로 설정
  devices: 1  # 사용하려는 디바이스 수
  logger:
    _target_: pytorch_lightning.loggers.TensorBoardLogger
    save_dir: logs/  # 로그를 저장할 디렉토리
    name: default  # 로그 이름

  log_every_n_steps: 10
  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: "val_loss_mse"
      dirpath: "checkpoints"
      filename: "model-{epoch:02d}-{val_loss_mse:.2f}"
      save_top_k: 3
      mode: "min"

seed: 42
debug: false



# Titans_project/configs/data/dataset.yaml

data:
  csv_path: "/home/user/imjaegyun/Titans_model/Titans_project/datasets/DJI_0023_stab.csv"
  video_path: "/home/user/imjaegyun/Titans_model/Titans_project/datasets/DJI_0023_stab.mp4"
  train_size: 70  # 예시 값, 실제 데이터에 맞게 조정
  val_size: 20    # 예시 값, 실제 데이터에 맞게 조정
  test_size: 10   # 추가된 부분
  train_batch_size: 4
  val_batch_size: 4
  test_batch_size: 4  # 추가된 부분
  frames_per_second: 10
  past_sec: 1
  future_steps: 2  # 추가된 부분



# Titans_project/configs/model/titan.yaml

model:
  # Light-weight LLM (tokenizer-only)
  lightweight_llm:
    model_name: "meta-llama/Llama-3.2-1B"  # tokenizer만 사용
    lr: 1e-5
    use_lora: false

  # ViT(EAGLE) - 예시
  vit_eagle:
    model_name: "google/vit-base-patch16-224"
    freeze: true

  # Trajectory Encoder
  trajectory_encoder:
    input_dim: 2  # 수정된 부분: 2로 변경
    hidden_dim: 128

  # Base LLM
  base_llm:
    model_name: "meta-llama/Llama-3.2-1B"
    tokenizer_name: "meta-llama/Llama-3.2-1B"
    freeze: true
    use_lora: true
    hidden_size: 2048  # 수정된 부분

  # Titans
  titans:
    d_model: 2048  # 수정된 부분
    memory_depth: 2
    decoder_layers: 2
    surprise_decay: 0.9
    momentum: 0.9
    forget_alpha: 0.1

  # Optimizer
  optimizer:
    lr: 1e-4
    weight_decay: 1e-2


